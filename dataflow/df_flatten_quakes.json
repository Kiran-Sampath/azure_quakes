{
	"name": "df_flatten_quakes",
	"properties": {
		"description": "",
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"dataset": {
						"referenceName": "ds_adls_quakes",
						"type": "DatasetReference"
					},
					"name": "source1"
				}
			],
			"sinks": [
				{
					"dataset": {
						"referenceName": "ds_sql_alerts",
						"type": "DatasetReference"
					},
					"name": "sink1"
				},
				{
					"dataset": {
						"referenceName": "ds_sql_quakes",
						"type": "DatasetReference"
					},
					"name": "regular"
				}
			],
			"transformations": [
				{
					"name": "flatten1"
				},
				{
					"name": "derive1"
				},
				{
					"name": "filterdq"
				},
				{
					"name": "split1"
				}
			],
			"scriptLines": [
				"source(output(",
				"          bbox as double[],",
				"          features as (geometry as (coordinates as double[], type as string), id as string, properties as (alert as string, cdi as string, code as string, detail as string, dmin as double, felt as string, gap as short, ids as string, mag as double, magType as string, mmi as string, net as string, nst as short, place as string, rms as double, sig as short, sources as string, status as string, time as long, title as string, tsunami as boolean, type as string, types as string, tz as string, updated as long, url as string), type as string)[],",
				"          metadata as (api as string, count as short, generated as long, status as short, title as string, url as string),",
				"          type as string",
				"     ),",
				"     allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     ignoreNoFilesFound: false,",
				"     documentForm: 'singleDocument') ~> source1",
				"source1 foldDown(unroll(features),",
				"     mapColumn(",
				"          id = features.id,",
				"          properties_time = features.properties.time,",
				"          properties_updated = features.properties.updated,",
				"          mag = features.properties.mag,",
				"          place = features.properties.place,",
				"          url = features.properties.url,",
				"          felt = features.properties.felt,",
				"          tsunami = features.properties.tsunami,",
				"          sig = features.properties.sig,",
				"          type = features.properties.type,",
				"          coords = features.geometry.coordinates",
				"     ),",
				"     skipDuplicateMapInputs: false,",
				"     skipDuplicateMapOutputs: false) ~> flatten1",
				"flatten1 derive(time_utc = toTimestamp(toString(round(properties_time / 1000)), 's'),",
				"          updated_utc = toTimestamp(toString(round(properties_updated / 1000)), 's'),",
				"          lon = toFloat(coords[1]),",
				"          lat = toFloat(coords[2]),",
				"          depth_km = toFloat(coords[3])) ~> derive1",
				"derive1 filter(!isNull(lon) && !isNull(lat) && (isNull(mag) || (mag >= -1 && mag <= 10))",
				") ~> filterdq",
				"filterdq split(mag > 5.0,",
				"     disjoint: false) ~> split1@(Alerts, Regular)",
				"split1@Alerts sink(allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     deletable:false,",
				"     insertable:true,",
				"     updateable:false,",
				"     upsertable:false,",
				"     format: 'table',",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     errorHandlingOption: 'stopOnFirstError') ~> sink1",
				"split1@Regular sink(allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     deletable:false,",
				"     insertable:true,",
				"     updateable:false,",
				"     upsertable:false,",
				"     format: 'table',",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     errorHandlingOption: 'stopOnFirstError') ~> regular"
			]
		}
	}
}